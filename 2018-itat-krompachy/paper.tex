\documentclass{itatnew}
%% !!!dolezite: ak pisete po slovensky alebo po cesky pouzite
%% \documentclass[slovensky]{itatnew}
%% \documentclass[cesky]{itatnew}

\begin{document}

\title{Phonetic Transcription by Untrained Annotators}

\author{Oldřich Krůza\inst{1}}

\institute{ÚFAL MFF UK,\\
\email{kruza@ufal.mff.cuni.cz},\\ WWW home page:
\texttt{http://sixtease.net/}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
The paper presents an application for lay, untrained users to generate
high-quality phonetic transcription of speech. The application has been in use
for several years and has served to transcribe over 600 thousand word forms over
two versions of a web interface. In this paper, I present measures for
compensating the lack of expert training.
\end{abstract}

\section{Introduction}

\subsection{Our Setting}

The work presented in this paper is a part of the project that tends the spoken
corpus of Karel Mako\v{n}\cite{hajek2007cesky}. The corpus is of the single
speaker and has been recorded in amateur conditions, while the author was
speaking to his friends about a novel way to interpret the teaching of Jesus and
of mystic and spirituality in general. Karel Makoň died in 1993 and a community
of favorers of his teachings has persevered since then.

There are over 1000 hours of digitized recordings of Karel Makoň, they are
accessible under the CC-BY license and the project aims at bringing the most
benefit from them. The first step was digitizing the recordings from the
original magnetic tapes, the second step was releasing all of them on the
world-wide web, the third step was developing a web-based system for human /
machine transcription of the bulk, allowing for search.

The transcription we do is both phonetic and ortographic\footnote{There is no
actual focus on ortography. Instead, we mean the natural way of transcribing the
speech to human-readable text. Where it matters, focus is directed at precise
correspondence with the utterances instead of language cleanliness}. Our users
are supposed provide ortographic transcription where the pronunciation is
standard and phonetic otherwise.

\section{Annotator Expertise}

Our case is on the edge of what can be called linguistic data annotation. In our
lucky part of the world where alphabetization nears 100\%, transcription of
speech is hardly expert work. On the other hand, ensuring that the transcription
exactly matches the audio
\begin{itemize}
\item{as a representation of the words uttered and their meaning,}
\item{on the phonetic level, phoneme for phoneme,}
\item{on the time axis}
\end{itemize}
is beyond what can be expected from an untrained user.

Linguistic data annotation in general requires trained personnel. If we only
look at the Prague Dependency Treebank, we can notice the annotators provided
such a degree of expertise they have become the
co-authors\cite{hajivc2005complex}.

Crowdsourcing, community-driven approach or engaging volunteers is an ever
stronger, popular way of obtaining assets that would otherwise be unbearably
costly. Let us mention for example Mihalcea (2004)\cite{mihalcea2004building}
who delegates word-sense disambiguation to volunteers. The
Wikicorpus\cite{reese2010wikicorpus} as well as the MASC\cite{ide2010manually}
gather annotation from volunteers.

In most cases, quality is very important for data annotation, so some kind of
control is essential, no matter how expert the annotators. Trivially, the less
expertise, the more control is needed.

\subsection{Quality Control}

A common way of dealing with quality control is to inspect annotator agreement.
This has the huge downside that every piece of data must be annotated at least
twice, which reduces the yield by 50+\%.

There is another reason not to use it in our case. Our application is
designed for people who want to listen to the recordings out of interest and
their contribution to the quality of the transcription is more of a by-product.
It would be hard to convince them to choose exactly a recording that another
user has already transcribed.

Luckily, we can implement automatic measures to aid the annotators to deliver
higher-quality transcriptions.

\subsection{Forced Alignment}

Since we always assume an existing transcription, we can see the user's
contribution as a correction. Every submission has
the form of replacing a text segment with another. Since the transcriptions are
time-aligned to the audio, we also know exactly what is the corresponding audio
segment to the text submitted.

This enables us to perform forced alignment on the submitted text and the audio.
With a well selected pruning threshold, we can distinguish false transcriptions
and reject them, providing feedback to the contibutor.
Since every segment of audio fits the acoustic model to a different degree, both
false positives and false negatives will inevitably occur.

False positives (when the system accepts a wrong transcription) present a
problem, since the error will enter the data set. But false negatives can often
be circumvented by submitting the transcription divided in different segments.
Of course, this method can also be used to force a wrong transcription but we
assume no malevolence on the part of the users.

Apart from catching wrong transcription, the forced alignment mechanism provides
exact synchronization on the time axis. This is a completely missing element in
the case of virtually all programs for aiding manual transcription. For some
examples, Transcriber\footnote{http://trans.sourceforge.net/}, a veteran
open-source transcribing program for Linux, expects the user to provide
alignment on the level of phrases;
Transcribe\footnote{http://transcribe.wreally.com/}, a commercial web-based
transcribing tool, allows the user to add timestamps anywhere in the text. There
is no acoustic model, hence nothing to match against.

\end{document}
