\documentclass{llncs}
%\usepackage[cp1250]{inputenc}
%\usepackage[utf8]{inputenc}
%\usepackage[czech]{babel}
\usepackage{graphicx}
\usepackage{tabularx}
%\usepackage{tipa}

\bibliographystyle{splncs}

\begin{filecontents}{citace.bib}
@inproceedings{kruuza2012making,
  title={Making Community and ASR Join Forces in Web Environment},
  author={Kr{\uu}za, Old{\v{r}}ich and Peterek, Nino},
  booktitle={International Conference on Text, Speech and Dialogue},
  pages={415--421},
  year={2012},
  organization={Springer}
}
\end{filecontents}



\begin{document}
\newtheorem{Definition}{Definition}
\title{ASR-Output-Correcting Webapp After 6 Years}

\author{Oldřich Krůza and Vladislav Kuboň}
\institute{Charles University in Prague\\
           Faculty of Mathematics and Physics\\
           Institute of Formal and Applied Linguistics\\
           Malostranské nám. 25, Prague, Czech Republic\\
           \{kruza,vk\}@ufal.mff.cuni.cz}

\maketitle

\begin{abstract}

This paper presents a next-generation web application that enables users to
contribute corrections to automatically acquired transcription of long speech
recordings. We describe differences from similar settings, compare our solution
with others and reflect on the development from the first, 6 years old version
in the light of the work done, lessons learned and the new technologies
available in the browser.

\end{abstract}

\section{Introduction}

In 2012\cite{kruuza2012making}, we presented a setting where a community of
users contributed corrections to automatically transcribed talks of a single
speaker. Now that the browser technologies evolved drastically and we could
observe the usage patterns and discover shortcomings of the solution at hand, we
have created a next generation of the programme. We shall describe the steps
taken and discuss their motivation and impact.

\section{Differences to other settings}

In our setting, we have a large spoken corpus (about 1000 hours) of a single
speaker. Our aim is to have a transcription as good as possible for the purpose
of searching and further, higher-level processing of the data. There is a pool
of people interested in the talks, who on one hand are the force we can try to
employ and on the other hand are the consumers of our effort, our target group
so to speak.

The web application should therefore combine the two purposes: 1. serve its user
with making the content available in a manner as good as possible and 2. animate
the user to give as much and as high-quality contribution as possible.

To our best knowledge, there is no other project with a comparable setting.
However, we can compare single aspects found in other applications.

\subsection{Transcribing apps}

The main differences to common transcribing software are that

\noindent
\begin{tabularx}{\textwidth}{
    @{\hspace{1.5em}}% Space for left bullet
    >{\leavevmode\llap{\textbullet~}\raggedright}% Left bullet + formatting of column
    X% Left column specification
    @{\quad\hspace{1.5em}}% Space between columns + right bullet space
    >{\leavevmode\llap{\textbullet~}\raggedright\arraybackslash}% Right bullet + formatting of column
    X% Right column specification
    @{}% No column space on right
  }
  \em{common transcription applications} & \em{our application} \\
  are optimized for the case where there is no transcription available and it
  must be acquired from scratch &
    always assumes a transcription is available \\
  need no quality control: the user is free to enter whatever transcription she
  pleases and the ultimate measure is her satisfaction &
    needs the transcription to be accurate because it is used as training data
    for the acoustic model \\
  use alignment on the level of phrases, if any &
    uses alignment on the level of words \\
  are user-centric: the user transcribes whatever acoustic data they choose &
    is data-centric: the whole application with all its tools and persons
    revolves around the data set \\
  assumes the user wants to transcribe &
    assume the user want to listen and possibly read along and we want to
    animate her to submit transcriptions \\
  has no shared data between users &
    must count with collisions
\end{tabularx}

We can still learn a lot from transcribing software. The ease of performing
common tasks, like pausing, resuming and rewinding is crucial for the user
experience and in effect for the amount of submissions that we receive. Also,
the way the text is displayed synchronously to the audio played has a big impact
and the approaches have a lot of space for variation.

\subsection{Wiki}

Where our application diverts from transciption software, it mostly resembles a
wiki: a community platform that serves its users including the contributors but
where the quality of the contributions is essential, while the contributor's
satisfaction alone is of little importance.

%The need for quality control has wide implications. We need to perform forced
%alignment every time a segment is transcribed. Hence, it must be clear what part
%of the audio \em{exactly} the segment corresponds to. Since each word knows its
%exact timestamp, and we know which words from the old transcription are to be
%replaced, we can perform the forced alignment very precisely. This is also one
%of the reasons why our application always assumes an existing transcription.

%What concerns animating the user to provide a transcription, there must be more
%research done. The basic idea is though that when the user sees the
%transcription synchronously and it contains errors, they get the urge to fix it.

%Our first reference is
%Transcriber\footnote{sourceforge.net/projects/trans}. Transcriber is an
%open-source program written in TCL.

\section{Conclusion}

\section*{Acknowledgments}

The research was supported by SVV project number 265 314.\\
\\
This work has been using language resources stored
by the LINDAT-Clarin project of the Ministry of
Education of the Czech Republic (project LM2010013).
%\bibliography{paper}

\bibliography{citace}

\end{document}
